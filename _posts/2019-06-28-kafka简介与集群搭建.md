---
layout: post
title: "kafka简介与集群搭建"
date: 2019-06-28
tags: java
---

Kafka 是一款分布式消息发布和订阅系统，具有高性能、高吞吐量的特点而被 广泛应用与大数据传输场景。

由于 kafka 具有更好的吞吐量、内置分区、冗余及容错性的优点(kafka 每秒可 以处理几十万消息)，让 kafka 成为了一个很好的大规模消息处理应用的解决方案。

### Kafka的应用场景

** 行为跟踪：**kafka 可以用于跟踪用户浏览页面、搜索及其他行为。通过发布订阅模式实时记录到对应的 topic 中，通过后端大数据平台接入处理分析，并 做更进一步的实时处理和监控

**日志收集：**日志收集方面，有很多比较优秀的产品，比如 Apache Flume，很多公司使用 kafka 代理日志聚合。日志聚合表示从服务器上收集日志文件，然后放到一个集中的平台（文 件服务器）进行处理。在实际应用开发中，我们应用程序的 log 都会输出到本地的磁盘上， 排查问题的话通过 linux 命令来搞定，如果应用程序组成了负载均衡集群，并且集群的机器 有几十台以上，那么想通过日志快速定位到问题，就是很麻烦的事情了。所以一般都会做一 个日志统一收集平台管理 log 日志用来快速查询重要应用的问题。所以很多公司的套路都是 把应用日志几种到 kafka 上，然后分别导入到 es 和 hdfs 上，用来做实时检索分析和离线 统计数据备份等。而另一方面，kafka 本身又提供了很好的 api 来集成日志并且做日志收集

### Kafka 本身的架构

kafka包含 Producer，Broker（kafka 支持水平扩展）、Consumer Group，以及zookeeper 集群。kafka 通过 zookeeper 管理集群配置及服务协同。Producer 使用 push 模式将消息发布到 broker，consumer 通过监听使用 pull 模式从 broker 订阅并消费消息。 多个 broker 协同工作，producer 和 consumer 部署在各个业务逻辑中。三者通过 zookeeper 管理协调请求和转发。这样就组成了一个高性能的分布式消息发布和订阅系统。 图上有一个细节是和其他 mq 中间件不同的点，producer 发送消息到 broker 的过程是 push，而 consumer 从 broker 消费消息的过程是 pull，主动去拉数 据。而不是 broker 把数据主动发送给 consumer

![image](https://upload-images.jianshu.io/upload_images/14890912-9827679af18e0378?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![image.gif](https://upload-images.jianshu.io/upload_images/14890912-3172ea19861bdfd7.gif?imageMogr2/auto-orient/strip) 

### kafka的集群安装部署(需要准备zookeeper)

搭建3台kafka集群

首先在每台服务器安装好JDK

下载kafka

[http://kafka.apache.org/downloads](http://kafka.apache.org/downloads)     我下的是 [kafka_2.11-2.2.1.tgz](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.2.1/kafka_2.11-2.2.1.tgz) 版本

1\. tar -zxvf kafka_2.11-2.2.1.tgz   解压安装包

2. cd kafka_2.11-2.2.1

3\. vi config/server.properties

### 修改 server.properties 配置

4 修改 zookeeper.connect=172.16.19.186:2181      (zk的地址)

5\. 修改 broker.id=0   (broker的全局唯一编号，集群的kafka不能重复，和zookeeper的myid是一个意思)

6\. 修改 listeners=PLAINTEXT://192.168.79.138:9092  (broker监听IP和端口也可以是域名，修改成当前kafka服务器的ip和端口)

7.修改 num.partitions=3   (创建topic时设置分区数量，当建立Topic时不指定分区数量，默认的数量是这里设置的，一般需要看服务器的吞吐量来设置，但都会设置成至少与borck数量相同，因为这样有能把topic的分区分配到每台brock上，才能实现集群容错)

8.在最后面添加 default.replication.factor=2 (表示创建一个分区和一个分区的副本，就是有两个相同的分区，一个leader，一个fowller)

(一个topic，默认分区的replication(副本)个数，设置成1表示只创建分区本身(分区本身也是个副本，是[Leader](http://www.baidu.com/link?url=4s8-AhXX1Ig7M3wDFvq9MrpbIns72lavq6jzW2wGY_UytVnk9frrYXPRFGwb4NSwPhg2EYvCWQUyccdI5sRjnCM1OUvqUDLSDMSLOqyVGRC)副本) ，不得大于集群中broker的个数，可以设置成2(每个分区有一个副本备份数据)，这样每个分区就会多一个副本，就能起容错效果，如果某个brock有p0分区(p0分区[Leader](http://www.baidu.com/link?url=4s8-AhXX1Ig7M3wDFvq9MrpbIns72lavq6jzW2wGY_UytVnk9frrYXPRFGwb4NSwPhg2EYvCWQUyccdI5sRjnCM1OUvqUDLSDMSLOqyVGRC))，但这个borck挂了，另一台borck上还有p0分区(follwer)的副本，这个p0 follwer副本，会成为leader，消费者能正常消费到p0上的消息)


配置完成

([https://blog.51cto.com/littledevil/2134694?source=dra](https://blog.51cto.com/littledevil/2134694?source=dra))这篇文件有其他的配置参数说明。这里配置上面5个基本就可以了

3台kafka都是相同的操作

### 启动

先启动zookeeper

然后分别启动3台kafka       id最小的会选为master

启动命令：到kafka的bin目录执行 

sh kafka-server-start.sh ../config/server.properties &

启动成功到zk -client上查询brock的节点数

![image](https://upload-images.jianshu.io/upload_images/14890912-ef904294f3ceb0c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![image.gif](https://upload-images.jianshu.io/upload_images/14890912-ad7aa0200b0ae19b.gif?imageMogr2/auto-orient/strip) 

查询到有 0 1 2三台kafka brock节点  (显示的是broker.id)

搭建成功